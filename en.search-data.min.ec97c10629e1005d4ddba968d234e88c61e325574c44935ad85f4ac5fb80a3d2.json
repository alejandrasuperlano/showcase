[{"id":0,"href":"/showcase/docs/Taller-1/1-Visual-Illusions/","title":"1) Visual Illusions","section":"Taller 1","content":" Visual Illusions üëÅ # Workshop Estudie, implemente y discuta posibles aplicaciones de algunos fen√≥menos visuales e ilusiones √≥pticas conocidas.\nIllusion 1: Stepping Feet üë£ # Marco Teorico # La ilusi√≥n \u0026ldquo;Stepping Feet\u0026rdquo; es un fen√≥meno de percepci√≥n del movimiento, donde se percibe que el recuadro azul y amarillo var√≠an sus velocidades relativa de manera dram√°tica, aunque en realidad su movimiento es constante.\n¬øQu√© est√° pasando? Cuando el recuadro azul se encuentra sobre las l√≠neas blancas, el contraste es alto, por lo cual el movimiento se percibe m√°s r√°pido que su velocidad real. Por otro lado, cuando el recuadro se encuentra sobre las l√≠neas negras, el contraste resultante es bajo y m√°s dif√≠cil de ver.\nEl efecto contrario ocurre para el recuadro amarillo, resultando en la ilusi√≥n de que los recuadros dan pasos alternadamente.\nDebido a lo anterior, cuando el contraste desaparece, es posible ver que los recuadros se mueven a la misma velocidad.\nSolucion y resultados # Este efecto es m√°s pronunciado cuando se fija la visi√≥n en la zona entre los recuadros. ‚Äº Haz click en el canvas para revelar la ilusi√≥n. Source Code # let x = 0; // Posici√≥n en x de los recuadros let vx = 0.5; // Velocidad de desplazamiento let w = 50; // Ancho de los recuadros function setup() { createCanvas(400, 250); colorMode(RGB, 255); } function draw() { // De acuerdo al mouseIsPressed se pinta un fondo con alto o bajo contraste if (mouseIsPressed) { lowContrastBackground(); } else { highContrastBackground(); } // Actualizaci√≥n de la velocidad cuando llega al limite del canvas if (x + vx \u0026gt; width - w || x + vx \u0026lt; 0) { vx *= -1; } // Actualizaci√≥n de la posici√≥n en cada iteraci√≥n x += vx; noStroke(); // Recuadro amarillo fill(color(244, 244, 0)); rect(x, 80, w, 20); // Recuadro azul fill(color(4, 4, 156)); rect(x, 160, w, 20); } function highContrastBackground() { for (let i = 0; i \u0026lt; 750; i += 9) { if (i % 2 == 0) { fill(242, 242, 242, 255); } else { fill(12, 12, 12, 255); } rect(i, 0, 9, 400); } } function lowContrastBackground() { for (let i = 0; i \u0026lt; 750; i += 9) { if (i % 2 == 0) { fill(140); } else { fill(116); } rect(i, 0, 9, 400); } } Illusion 2 : Stereokinetic Effect (SKE) üßø # Marco Teorico # La rotaci√≥n de las figuras adecuadas puede crear una ilusi√≥n tridimensional. Un ejemplo que permite demostarlo es el efecto estereocin√©tico el cual una ilusi√≥n de profundidad. Puede pasar alg√∫n tiempo hasta que surja la percepci√≥n.\n¬øQu√© es el efecto estereocin√©tico?\nEl efecto estereocin√©tico (SKE) se ha definido y estudiado mediante patrones circulares anidados que giran en una plataforma giratoria. Los c√≠rculos deben parecer que no giran, lo que a su vez da lugar a que parecen trasladarse unos a otros. Solucion y resultados # A continuaci√≥n, podemos observar un ejemplo de lo mencionado anteriormente: Manten el click en el canvas para ver otro tipo de efecto !. Se ha comprobado que las visualizaciones consistentes en simples traslaciones evocan impresiones de profundidad s√≥lidas.\nMusatti (1924) public√≥ el primer informe sobre los fen√≥menos estereocin√©ticos y atribuy√≥ su descubrimiento y denominaci√≥n a su maestro profesor, Vittorio Benussi Como se observa en la ilusi√≥n, un conjunto de anillos conc√©ntricos gira como si estuviera en una plataforma giratoria. Un conjunto m√°s peque√±o de anillos en el centro gira alrededor de un eje diferente, lo que puede dar la ilusi√≥n de que estos anillos m√°s peque√±os tienen profundidad espacial.\nImagen 1 : Efecto estereocin√©tico (SKE) tradicional girada 90¬∞.\nSource Code # A continuaci√≥n se muestran las funci√≥nes principales las cuales permitieron crear esta ilusion:\nclass Circle { constructor(r, coordR, color) { this.r = r; this.coordR = coordR; this.color = color; } render(centerX, centerY, angle) { const coord = polarCoordinates(this.coordR, angle); const x = coord.x; const y = coord.y; noStroke(); fill(this.color); circle(centerX + x, centerY + y, this.r); } } function polarCoordinates(r, angle) { let x = 0; y = 0; x = r * cos(angle); y = r * sin(angle); return { x, y }; } function renderingCirles() { for (let i = 0; i \u0026lt; circles.length; i++) { circles[i].render(centerX, centerY, angle); } } Aplicaciones # Los candidatos m√°s l√≥gicos son los sistemas que requieren movimiento en tiempo real pero en los que las limitaciones de coste, tama√±o o fiabilidad impiden el uso de motores de geometr√≠a 3D.\nMapas de contorno en movimiento : Los mapas de contorno se utilizan en la navegaci√≥n por la siesta, La tripulaci√≥n correlaciona las caracter√≠sticas del terreno vistas fuera de la cabina con las caracter√≠sticas representadas en el mapa para lograr y mantener la orientaci√≥n geogr√°fica. Imagen 2 : Una l√≠nea de elevaci√≥n constante representada en una superficie y en un mapa de contorno.\nPantalla de control del tr√°fico a√©reo: Al enrutar y poner en cola el tr√°fico a√©reo, los controladores necesitan recuperar las relaciones espaciales en 3D entre las aeronaves.\nSe han desarrollado y evaluado varios formatos de visualizaci√≥n alternativos que utilizan se√±ales de perspectiva\nImagen 3 : Pantalla de control de tr√°fico aereo.\nConclusiones # Es √∫til estudiar las ilusiones √≥pticas y ‚ÄúVisual Artifacts‚Äù que existen, de modo que se eviten o apliquen de manera estrat√©gica cuando sea pertinente, para lograr alg√∫n objetivo visual. Referencias # Stereokinetic Effect.Neurobs. https://www.neurobs.com/manager/content/docs/psychlab101_experiments/Stereokinetic%20Effect/description.html\nProffitt, D. R., Rock, I., Hecht, H., \u0026amp; Schubert, J. (1992). Stereokinetic effect and its relation to the kinetic depth effect. Journal of Experimental Psychology: Human Perception and Performance, 18(1), 3‚Äì21. https://doi.org/10.1037/0096-1523.18.1.3\nG. (2018, 8 noviembre). ¬øQu√© son las isol√≠neas, contornos o curvas de nivel? El blog de franz. https://acolita.com/que-son-las-isolineas-contornos-o-curvas-de-nivel/\n"},{"id":1,"href":"/showcase/docs/Taller-1/2-Visual-Masking/","title":"2) Visual Masking","section":"Taller 1","content":" Visual Masking üí° # Workshop Implementar una aplicaci√≥n web de procesamiento de imagenes que soporte varios kernels y adem√°s:\nVisualizaci√≥n de histograma de la imagen Diferentes herramientes de luminosidad Marco te√≥rico # Kernel # Un kernel o mascara es una matriz usada para aplicar algun tipo de efecto como difuminado, detecci√≥n de bordes , sobre una imagen. Eso se logra realizando una convoluci√≥n entre el kernel y la imagen. ¬øQu√© es una convoluci√≥n?\nEn procesamiento de imagenes, una convoluci√≥n consiste en multiplicar cada p√≠xel de la imagen por la entrada correspondiente del kernel, luego al sumar todos los resultados, se obtiene el valor del nuevo p√≠xel. A modo de ejemplo, se escogieron los siguientes kernels para mostrar su aplicaci√≥n:\nSharpening \\[\\begin{bmatrix} 0 \u0026amp; -1 \u0026amp; 0\\\\ -1 \u0026amp; 5 \u0026amp; -1\\\\ 0 \u0026amp; -1 \u0026amp; 0\\\\ \\end{bmatrix}\\] Emboss \\[\\begin{bmatrix} -2 \u0026amp; -1 \u0026amp; 0\\\\ -1 \u0026amp; 1 \u0026amp; 1\\\\ 0 \u0026amp; 1 \u0026amp; 2\\\\ \\end{bmatrix}\\] Blur \\[\\begin{bmatrix} 0.0625 \u0026amp; 0.125 \u0026amp; 0.0625\\\\ 0.125 \u0026amp; 0.25 \u0026amp; 0.125\\\\ 0.0625 \u0026amp; 0.125 \u0026amp; 0.0625\\\\ \\end{bmatrix}\\] Histograma # Un histograma de una imagen consiste en la representaci√≥n gr√°fica de la distribuci√≥n tonal de la imagen, trazando el n√∫mero de p√≠xeles de cada canal.\nEn el eje horizontal representa las variaciones tonales, mientras que el vertical, representa la cantidad de p√≠xeles en un tono particular.\n¬øC√≥mo interpretar un histograma?\nEl lado izquierdo del eje horizontal representa las √°reas oscuras y el derecho representa las √°reas iluminadas.\nPor ejemplo, para una imagen oscura, esta tendr√° la mayor√≠a de puntos dibujados en el lado izquiero del histograma.\nHerramientas de luminosidad # La luminosidad es la percepci√≥n visual de la luminancia de un objeto. En colorimetr√≠a, es una predicci√≥n de que tan iluminado aparecer√° un color para un determinado observador. ¬øQu√© es la luminancia? Es la m√©dida de intensidad lum√≠nica por unidad de √°rea de la luz viajando en una determinada direcci√≥n. Es decir, describe la cantidad de luz que pasa a trav√©s, es emitida o reflejada de un √°rea particular.\nExisten varias formas de calcular la luminosidad de un color. A modo de ejemplo, se mostrar√°n las siguientes 4: Media aritm√©tica \\[I=\\frac{R\u0026#43;G\u0026#43;B}{3}\\] HSV \\[V=max(R,G,B)\\] HSL \\[L=\\frac{max(R,G,B)\u0026#43;min(R,G,B)}{2}\\] Luma \\[Y=0.2126\\cdot R\u0026#43; 0.7152\\cdot G\u0026#43;0.0722\\cdot B\\] Soluci√≥n y resultados # Kernel # A continuaci√≥n se muestra la funci√≥n principal, la cual es la encargada de calcula el nuevo valor de cada p√≠xel:\nlet applyKernelToPixel = (x, y, kernel, kernelSize) =\u0026gt; { let newR = 0.0; let newG = 0.0; let newB = 0.0; // Go through each kernel entry for (let r = 0; r \u0026lt; kernelSize; r++) { for (let c = 0; c \u0026lt; kernelSize; c++) { // Compute the offset let rowOffset = 1 - r; let colOffset = 1 - c; let imageRow = x - rowOffset; let imageCol = y - colOffset; let currentPixel = originalImg.get(imageRow, imageCol); // Compute new value for each channel newR += p.red(currentPixel) * kernel[r][c]; newG += p.green(currentPixel) * kernel[r][c]; newB += p.blue(currentPixel) * kernel[r][c]; } } // In case the new value is greater than 255 newR = p.constrain(newR, 0, 255); newG = p.constrain(newG, 0, 255); newB = p.constrain(newB, 0, 255); return p.color(newR, newG, newB); }; Histograma # A continuaci√≥n se muestra la funci√≥n principal, la cual es la encargada de contar la cantidad de p√≠xeles en cada valor de un determinado canal:\nlet countPixels = () =\u0026gt; { // Go through each pixel for (let x = 0; x \u0026lt; img.width; x++) { for (let y = 0; y \u0026lt; img.height; y++) { let pixel = img.get(x, y); // Add 1 to the current tonal value let value = currentColor === \u0026#34;red\u0026#34; ? p.red(pixel) : currentColor === \u0026#34;green\u0026#34; ? p.green(pixel) : p.blue(pixel); pixels[value] += 1; } } }; Herramientas de luminosidad # A continuaci√≥n, se muestra la implementaci√≥n de las 4 maneras de calcular la luminosidad expuestas anteriormente, junto con la funci√≥n encargada de aplicar ese c√°lculo a cada pixel de la imagen:\nlet lightnessModes = { mean: (color) =\u0026gt; { return (p.red(color) + p.green(color) + p.blue(color)) / 3; }, hsv: (color) =\u0026gt; { return Math.max((p.red(color), p.green(color), p.blue(color))); }, hsl: (color) =\u0026gt; { let max = Math.max((p.red(color), p.green(color), p.blue(color))); let min = Math.min((p.red(color), p.green(color), p.blue(color))); return (max + min) / 2; }, luma: (color) =\u0026gt; { return ( 0.2126 * p.red(color) + 0.7152 * p.green(color) + 0.0722 * p.blue(color) ); }, }; let applyLightness = (mode) =\u0026gt; { // Extract the current function let lightness = lightnessModes[mode]; // Go through each pixel for (let i = 0; i \u0026lt; originalImg.width; i++) { for (let j = 0; j \u0026lt; originalImg.height; j++) { let newPixel = lightness(originalImg.get(i, j)); currentImg.set(i, j, p.color(newPixel)); } } }; Conclusiones # La aplicaci√≥n de una convoluci√≥n usando un kernel a una imagen se ver√≠a en extremo beneficiada por la paralelizaci√≥n de dicha aplicaci√≥n Se deben considerar todas las formas de calcular la luminosidad de una imagen a la hora de pasar la imagen a escala de grises "},{"id":2,"href":"/showcase/docs/Taller-2/1-WebGL-3D-App/","title":"1) Web Gl 3 D App","section":"Taller 2","content":" 3D APP : 3D Audio Visualizer üé∂ # Workshop Implement a 3d webgl application. The p5.treegl or any other libraries may be used\nMarco te√≥rico # Se√±ales electromagn√©ticas # Como componente te√≥rico principal de la aplicaci√≥n, se tienen las se√±ales de electromagn√©ticas, las cuales, a manera de resumen, se pueden descomponer en varias ondas sinusoidales peri√≥dicas, y cada una tiene una serie de caracter√≠sticas propias de una onda electromagn√©tica. En particular, nos interesan 2 de estas:\nFrecuencia: Es la medida del n√∫mero de ciclos o repeticiones de la onda por unidad de tiempo. Amplitud: Es el desplazamiento m√°ximo que experimenta un punto de una onda respecto a la posici√≥n de equilibrio Transformada de Fourier # Es usada para transformar se√±ales entre el dominio del tiempo o espacio al dominio de la frecuencia, y viceversa. Se define matem√°ticamente as√≠: A continuaci√≥n, se muestra una comparaci√≥n del dominio del tiempo y de la frecuencia de una onda sinusoidal.\nLa Transformada de Fourier tiene su versi√≥n discreta que facilita su implementaci√≥n computacional, la cual est√° definida as√≠: Transformada Discreta de Fourier (DFT):\nPor √∫ltimo, existe un algoritmo que reduce la complejidad de la implementaci√≥n de la DFT, el cual se conoce como la Transformada R√°pida de Fourier (FFT), y este es el algoritmo que usa el analizador de audio de Javascript.\nLa mayor√≠a de los analizadores de FFT permiten la transformaci√≥n de 512, 1024, 2048 o 4096 muestras.\nSource Code # Coordenadas esf√©ricas # El sistema de coordenadas esf√©ricas se basa en la misma idea que las coordenadas polares y se utiliza para determinar la posici√≥n espacial de un punto mediante una distancia y dos √°ngulos. Source Code # Normalizer.js class Normalizer { constructor(audio) { // Singleton Pattern if (typeof Normalizer.instance === \u0026#34;object\u0026#34;) { return Normalizer.instance; } // Audio Settings this.audio = audio; this.audio.crossOrigin = \u0026#34;anonymous\u0026#34;; this.audioCtx = new (window.AudioContext || window.webkitAudioContext)(); this.audioSource = this.audioCtx.createMediaElementSource(this.audio); this.analyser = this.audioCtx.createAnalyser(); this.audioSource.connect(this.analyser); this.analyser.connect(this.audioCtx.destination); this.analyser.fftSize = 1024; // FFT (Transformada R√°pida de Fourier) this.bufferLength = this.analyser.frequencyBinCount; // Config this.scaleType = \u0026#34;linear\u0026#34;; this.playing = false; Normalizer.instance = this; return this; } getData() { this.dataArray = new Uint8Array(this.bufferLength); this.analyser.getByteFrequencyData(this.dataArray); if (this.scaleType == \u0026#34;log\u0026#34;) { this.scaleLogToLinear(); } return this.dataArray; } setLogScale(){this.scaleType = \u0026#39;log\u0026#39;;} setLinearScale(){this.scaleType = \u0026#39;linear\u0026#39;;} scaleLogToLinear(){ (...) } togglePlay(){(...)} } Soluci√≥n y resultados üéà # Aplicaciones # La visualizaci√≥n de m√∫sica es el proceso de interpretar el sonido con im√°genes. Tiene la capacidad de mapear las cualidades de una grabaci√≥n o composici√≥n con gr√°ficos mediante la interpretaci√≥n de se√±ales digitales o electr√≥nicas. El m√©todo utilizado para traducir aspectos de la m√∫sica en cualidades visuales determina el aspecto y la respuesta de la visualizaci√≥n.\nExisten miles de visualizadores de m√∫sica diferentes. Cada uno tiene una interpretaci√≥n diferente de c√≥mo se ve el sonido. La visualizaci√≥n de m√∫sica es un desarrollo que se puede decir es moderno, pero sus ra√≠ces se remontan a siglos atr√°s. Goethe e Isaac Newton propusieron teor√≠as sobre c√≥mo el sonido y la luz comparten frecuencias comunes.\nEl sonido y el color son fuente de inspiracion especialmente importante en general para los m√∫sicos. Por otro lado las cualidades t√≠mbricas del sonido est√°n fuertemente asociadas con el color y la textura e incluso las notas individuales tienen fuertes conexiones con el color para algunos m√∫sicos.\nLa forma en que nuestros sentidos se mezclan cuando experimentamos m√∫sica nunca se explicar√° por completo. Ese misterio es parte de lo que atrae a las personas a nuevas formas de visualizar la m√∫sica. Conclusiones # Esta aplicaci√≥n es una manera interactiva de \u0026ldquo;ver\u0026rdquo; el sonido. Una caracter√≠stica importante de la visualizaci√≥n de m√∫sica es que las visualizaciones son √∫nicas. Cuando se trata de representar m√∫sica visualmente, sabemos que hay m√°s factores involucrados que las cualidades medibles de una se√±al. Esta visualizaci√≥n de m√∫sica nos permite evidenciar lo que es posible cuando combinamos sonido y visi√≥n. Referencias # Wikipedia contributors. (2022, 11 octubre). Fourier transform. Wikipedia. Recuperado de https://en.m.wikipedia.org/wiki/Fourier_transform\nWikipedia contributors. (2022a, octubre 8). Fast Fourier transform. Wikipedia. Recuperado de https://en.m.wikipedia.org/wiki/Fast_Fourier_transform\nPromocionMusical.es. (2020, 15 enero). Qu√© es la Visualizaci√≥n de M√∫sica: Origen, Evoluci√≥n y Ejemplos. Recuperado de https://promocionmusical.es/visualizacion-musica\nSpeigato.¬øQu√© es la visualizaci√≥n de m√∫sica?. Recuperado de https://spiegato.com/es/que-es-la-visualizacion-de-musica\nKazuki Umeda. (2021, 15 julio) What We can Create w/ p5js \u0026amp; Spherical Coordinates.Recuperado de https://www.youtube.com/watch?v=SGHWZz5Mrsw\u0026ab_channel=KazukiUmeda\n"},{"id":3,"href":"/showcase/docs/Taller-3/1-Color-Blending/","title":"1) Color Blending","section":"Taller 3","content":" Color Blending üî¥üü†üü° # Exercises Averiguar el c√≥digo js de los sketches de ejemplo. Implementar otros modos de blending. Tomar esta referencia como un punto de partida. Marco te√≥rico # Color Mixing # Existen 3 tipos de mezcla de colores: aditivo, sustractivo y promedio.\nAditivo Por convenci√≥n, los 3 colores primarios son el rojo, el verde y el azul. La ausencia de luz de cualquier color corresponde con negro. Si se mezclan los 3 colores en mismas propociones, el resultado es neutral (blanco o gris). Utilizado para monitores de computador. Sustractivo Los 3 colores primarios son cyan, magenta y amarillo. Corresponde a la mezcla de sustancias fisicas: por ejemplo, pintura. El color de un elemento corresponde con el espectro de luz visible que no es absorbido por el material. Promedio Se obtiene un nuevo color, donde el brillo es igual al promedio entre dos colores. Diferente a mezcla aditiva, en cuanto a que esta genera colores m√°s claros. Diferente a mezcla substractiva, en cuando a que se generan color m√°s oscuros. Fragment Shader # El fragment shader define el color normalizado del fragmento de cada pixel, que debe asignarse siempre a la variable reservada gl_FragColor vec4 glsl.\nLa informaci√≥n correspondiente a los colores que se van a mezclar se pasan como una uniforme, al archivo fragment shader.\nprecision mediump float; uniform float brightness; uniform vec4 uMaterial1; uniform vec4 uMaterial2; void main() { gl_FragColor = brightness * uMaterial1 * uMaterial2; } En el codigo anterior, existen tres uniformes:\nBrighness : Factor arbitrario que afecta el brillo del color final. uMaterial1 : 1er color que se va a mezclar. uMaterial2 : 2do color que se va a mezclar. Source Code # Source Code let blendShader; let color1, color2, brightness; let modeSelect, mode, identity; let modeToFileName, modeToIdentity; const WIDTH = 500; const HEIGHT = 250; function preload() { // Lectura del Shader utilizando Tree modeToFileName = { \u0026#39;Multiply ‚ùå\u0026#39;: readShader(\u0026#39;/sketches/color_blending/mult.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }), \u0026#39;Multiply ‚ùå + Brightness üí°\u0026#39;: readShader(\u0026#39;/sketches/color_blending/multBrightness.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }), \u0026#39;Add ‚ûï\u0026#39; : readShader(\u0026#39;/sketches/color_blending/add.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }), \u0026#39;Difference ‚ûñ\u0026#39; : readShader(\u0026#39;/sketches/color_blending/difference.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }), \u0026#39;Darkest üåë\u0026#39; : readShader(\u0026#39;/sketches/color_blending/dark.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }), \u0026#39;Lightest üåû\u0026#39; : readShader(\u0026#39;/sketches/color_blending/light.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.NONE }), } modeToIdentity = { \u0026#39;Multiply ‚ùå\u0026#39;: [1.0, 1.0, 1.0, 1.0], \u0026#39;Multiply ‚ùå + Brightness üí°\u0026#39;: [1.0, 1.0, 1.0, 1.0], \u0026#39;Add ‚ûï\u0026#39; : [0.0, 0.0, 0.0, 0.0], \u0026#39;Difference ‚ûñ\u0026#39; : [0.0, 0.0, 0.0, 0.0], \u0026#39;Darkest üåë\u0026#39; : [1.0, 1.0, 1.0, 1.0], \u0026#39;Lightest üåû\u0026#39; : [0.0, 0.0, 0.0, 0.0], } } function setup() { createCanvas(WIDTH, HEIGHT, WEBGL); noStroke(); // El color se normaliza entre 0 y 1 colorMode(RGB, 1); // Creaci√≥n de los selectores de colores color1 = createColorPicker(color(0.8, 0.5, 0.3)); color1.position(10, 10); color2 = createColorPicker(color(0.9, 0.1, 0.4)); color2.position(width - 45, 10); // Creaci√≥n del slider de brightness // emits \u0026#39;brightness\u0026#39; uniform in [0.0, 1.0] ‚àà R brightness = createSlider(0, 1, 0.5, 0.05); brightness.position(width / 2 - 35, 15); brightness.style(\u0026#39;width\u0026#39;, \u0026#39;80px\u0026#39;); const defaultMode = \u0026#39;Multiply ‚ùå\u0026#39;; // Creaci√≥n de select de blendMode modeSelect = createSelect(); modeSelect.position(WIDTH/3, height - 30); modeSelect.style(\u0026#39;width\u0026#39;, `${WIDTH/3}px`); modeSelect.option(\u0026#39;Multiply ‚ùå\u0026#39;); modeSelect.option(\u0026#39;Multiply ‚ùå + Brightness üí°\u0026#39;); modeSelect.option(\u0026#39;Add ‚ûï\u0026#39;); modeSelect.option(\u0026#39;Difference ‚ûñ\u0026#39;); modeSelect.option(\u0026#39;Darkest üåë\u0026#39;); modeSelect.option(\u0026#39;Lightest üåû\u0026#39;); modeSelect.changed(mySelectEvent); // Default shader mode = defaultMode; blendShader = modeToFileName[mode]; identity = modeToIdentity[mode]; shader(blendShader); } function mySelectEvent(){ mode = modeSelect.value(); blendShader = modeToFileName[mode]; identity = modeToIdentity[mode]; shader(blendShader); } function draw() { // Variables de utilidad para el posicionamiento de los elementos en el canvas let padding = 0.1; let width = 0.55; let height = 1; // Obtensi√≥n de los colores desde los color pickers let color1Color = color1.color(); let color2Color = color2.color(); background(0); // //////////////// // // FIGURA IZQUIERDA // // //////////////// // // setUniform : Utilizado para definir las uniformes del objeto p5.Shader // -\u0026gt; Especificadas en el archivo blend.frag blendShader.setUniform(\u0026#39;uMaterial1\u0026#39;, [red(color1Color), green(color1Color), blue(color1Color), 1.0]); blendShader.setUniform(\u0026#39;uMaterial2\u0026#39;, identity); // Al definir la uniforme uMaterial2 como (1, 1, 1, 1) entonces el color resultante corresponde con // uMaterial1, debido a que se multiplican los colores en el fragment blendShader.setUniform(\u0026#39;brightness\u0026#39;, 1.0); // Al definir la uniforme brightness como 1 entonces no afecta el resultado; elemento identidad beginShape(); vertex(-(width+(width/2) + padding), height/2, 0); vertex(-(width/2 + padding), height/2, 0); vertex(-(width/2 + padding), -height/2, 0); vertex(-(width+(width/2) + padding), -height/2, 0); endShape(); // ////////////// // // FIGURA DERECHA // // ////////////// // // setUniform : Utilizado para definir las uniformes del objeto p5.Shader // -\u0026gt; Especificadas en el archivo blend.frag blendShader.setUniform(\u0026#39;uMaterial1\u0026#39;, identity); blendShader.setUniform(\u0026#39;uMaterial2\u0026#39;, [red(color2Color), green(color2Color), blue(color2Color), 1.0]); // Al definir la uniforme uMaterial1 como (1, 1, 1, 1) entonces el color resultante corresponde con // uMaterial2, debido a que se multiplican los colores en el fragment blendShader.setUniform(\u0026#39;brightness\u0026#39;, 1.0); // Al definir la uniforme brightness como 1 entonces no afecta el resultado; elemento identidad beginShape(); vertex(width/2 + padding, height/2, 0); vertex(width/2 + padding + width, height/2, 0); vertex(width/2 + padding + width, -height/2, 0); vertex(width/2 + padding, -height/2, 0); endShape(); // ////////////// // // FIGURA CENTRAL // // ////////////// // // setUniform : Utilizado para definir las uniformes del objeto p5.Shader // -\u0026gt; Especificadas en el archivo blend.frag blendShader.setUniform(\u0026#39;uMaterial1\u0026#39;, [red(color1Color), green(color1Color), blue(color1Color), 1.0]); blendShader.setUniform(\u0026#39;uMaterial2\u0026#39;, [red(color2Color), green(color2Color), blue(color2Color), 1.0]); // En este caso, el color resultante es el producto entre ambas uniformes; ambas toman sus colores propios. blendShader.setUniform(\u0026#39;brightness\u0026#39;, brightness.value()); // En este caso, la uniforme brightness toma el valor del slider; por lo cual afecta el resultado beginShape(); vertex( -(width/2), height/2, 0 ); vertex( width/2, height/2, 0 ); vertex( width/2, -height/2, 0 ); vertex( -(width/2), -height/2, 0 ); endShape(); } Soluci√≥n y resultados # Utilice el selector para cambiar el modo de mezcla (BlendMode). Conclusiones # Existen distintas maneras de combinar dos colores en un pixel. La estrategia para mezclar colores es dependiente al medio. En el campo de la computaci√≥n visual, nos concierne la mezcla aditiva. El uso de fragment shaders simplifica la manera como se define el color de un pixel, abstrayendo muchos pasos intermedios. Referencias # Wikipedia contributors. (2022, 9 noviembre). Color Mixing. Wikipedia. Recuperado de https://en.wikipedia.org/wiki/Color_mixing\nVisual Computing. (2022, 9 noviembre). Coloring. Visual Computing. Recuperado de https://visualcomputing.github.io/docs/shaders/coloring/\n"},{"id":4,"href":"/showcase/docs/Taller-3/2-Texturing-UV-Visualization-1/","title":"2) Texturing Uv Visualization 1","section":"Taller 3","content":" UV Visualization - Exercise 1 üî¥üü¢üîµ # Exercise Redefinir las coordenas de textura de la figura, para invertir la imagen de abajo.\nSoluci√≥n #1 # JavaScript: Ajustando coordenadas u \u0026amp; v en vertex # Construcci√≥n de la figura invirtiendo las coordenadas de la textura en el llamado a vertex.\nLa funci√≥n vertex tiene la siguiente estructura:\nvertex(x, y, [z], [u], [v]) Siendo los parametros los siguientes:\nx - x-coordinate of the vertex y - y-coordinate of the vertex z - z-coordinate of the vertex u - the vertex\u0026rsquo;s texture u-coordinate v - the vertex\u0026rsquo;s texture v-coordinate Source Code: JavaScript // Construcci√≥n de la figura invirtiendo las coordenadas de la textura // en el llamado a vertex let uvShader; function preload() { // No se pasa ninguna matriz al shader uvShader = readShader(\u0026#39;/showcase/sketches/uv_1/uv.frag\u0026#39;, { matrices: Tree.NONE, varyings: Tree.texcoords2 }); } function setup() { createCanvas(300, 300, WEBGL); noStroke(); shader(uvShader); textureMode(NORMAL); } function draw() { background(0); beginShape(); // La funci√≥n vertex tiene la siguiente estructura: // // vertex(x, y, [z], [u], [v]) // // Siendo los parametros los siguientes: // x - x-coordinate of the vertex // y - y-coordinate of the vertex // z - z-coordinate of the vertex // u - the vertex\u0026#39;s texture u-coordinate // v - the vertex\u0026#39;s texture v-coordinate vertex(-1, -1, 0, 1, 1); vertex( 1, -1, 0, 0, 1); vertex( 1, 1, 0, 0, 0); vertex(-1, 1, 0, 1, 0); endShape(); } Soluci√≥n y Resultados # Soluci√≥n #2 # FragmentShader: Ajustando la variable gl_FragColor # Construcci√≥n de la figura editando el mapeo de texturas en el fragment shader.\nEl fragment shader se define a continuaci√≥n:\nSource Code: Fragment Shader precision mediump float; varying vec2 texcoords2; void main() { // glsl swizzling is both handy and elegant // see: https://www.khronos.org/opengl/wiki/Data_Type_(GLSL)#Swizzling gl_FragColor = vec4(1.0 - texcoords2.x, 1.0 - texcoords2.y, 0.0, 1.0); } Debido a que normalizamos el modo de textura; logramos invertir la textura restando cada una de las componentes en x y y a 1.0\nSoluci√≥n y Resultados # Conclusi√≥n # Los fragment shaders simplifican el mapeo de texturas. Existen multiples maneras de editar el mapeo de texturas. Referencias # Visual Computing. (2022, 15 noviembre). Texturing. Visual Computing. Recuperado de https://visualcomputing.github.io/docs/shaders/texturing/ "},{"id":5,"href":"/showcase/docs/Taller-3/3-Texturing-UV-Visualization-2/","title":"3) Texturing Uv Visualization 2","section":"Taller 3","content":" UV Visualization - Exercise 2 üü•üü©üü¶ # Exercises Incluir el canal azul dentro de la visualizaci√≥n uv. Utilizar otras figuras, diferentes a quad, como filtros. Soluci√≥n y Resultados # Utilice el primer selector para cambiar los canales visualizados. Utilice el segundo selector para cambiar la forma del filtro. Conclusiones # Es posible implementar filtros pasando un parametro de opacidad como uniforme al fragment shader. Referencias # Visual Computing. (2022, 15 noviembre). Texturing. Visual Computing. Recuperado de https://visualcomputing.github.io/docs/shaders/texturing/ "},{"id":6,"href":"/showcase/docs/Taller-3/4-Color-Brightness-and-Tinting/","title":"4) Color Brightness and Tinting","section":"Taller 3","content":" Color Brightness and Tinting üë©‚Äçüé® # Soluci√≥n y Resultados # Utilice el 1er selector para cambiar el modo de brillo (Coloring Brightness Tool). Utilice el 2do selector para cambiar el modo de mezcla de colores (BlendMode). Utilice el checkbox para aplicar el tintado. Seleccione el color de tintado con el selector. "},{"id":7,"href":"/showcase/docs/Taller-3/5-Image-Processing/","title":"5) Image Processing","section":"Taller 3","content":" Image/Video processing üñºÔ∏è # "}]